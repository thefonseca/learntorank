{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "from rankpy.queries import Queries\n",
    "from rankpy.queries import find_constant_features\n",
    "from rankpy.models import LambdaMART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train queries: Queries (7375 queries, 44250 documents, 8 features, 1 max. relevance)\n",
      "Valid queries: Queries (1331 queries, 7986 documents, 8 features, 1 max. relevance)\n",
      "Test queries: Queries (1294 queries, 7764 documents, 8 features, 1 max. relevance)\n",
      "Train queries: Queries (4240 queries, 25440 documents, 8 features, 1 max. relevance)\n",
      "Valid queries: Queries (698 queries, 4188 documents, 8 features, 1 max. relevance)\n",
      "Test queries: Queries (1294 queries, 7764 documents, 8 features, 1 max. relevance)\n",
      "nDCG@3 on the test queries: 0.42834832\n",
      "Train queries: Queries (7339 queries, 44034 documents, 8 features, 1 max. relevance)\n",
      "Valid queries: Queries (1287 queries, 7722 documents, 8 features, 1 max. relevance)\n",
      "Test queries: Queries (1374 queries, 8244 documents, 8 features, 1 max. relevance)\n",
      "Train queries: Queries (4149 queries, 24894 documents, 8 features, 1 max. relevance)\n",
      "Valid queries: Queries (658 queries, 3948 documents, 8 features, 1 max. relevance)\n",
      "Test queries: Queries (1374 queries, 8244 documents, 8 features, 1 max. relevance)\n",
      "nDCG@3 on the test queries: 0.42864709\n",
      "Train queries: Queries (7300 queries, 43800 documents, 8 features, 1 max. relevance)\n",
      "Valid queries: Queries (1313 queries, 7878 documents, 8 features, 1 max. relevance)\n",
      "Test queries: Queries (1387 queries, 8322 documents, 8 features, 1 max. relevance)\n",
      "Train queries: Queries (4014 queries, 24084 documents, 8 features, 1 max. relevance)\n",
      "Valid queries: Queries (643 queries, 3858 documents, 8 features, 1 max. relevance)\n",
      "Test queries: Queries (1387 queries, 8322 documents, 8 features, 1 max. relevance)\n",
      "nDCG@3 on the test queries: 0.43610498\n",
      "Train queries: Queries (7338 queries, 44028 documents, 8 features, 1 max. relevance)\n",
      "Valid queries: Queries (1303 queries, 7818 documents, 8 features, 1 max. relevance)\n",
      "Test queries: Queries (1359 queries, 8154 documents, 8 features, 1 max. relevance)\n",
      "Train queries: Queries (4272 queries, 25632 documents, 8 features, 1 max. relevance)\n",
      "Valid queries: Queries (689 queries, 4134 documents, 8 features, 1 max. relevance)\n",
      "Test queries: Queries (1359 queries, 8154 documents, 8 features, 1 max. relevance)\n",
      "nDCG@3 on the test queries: 0.46769734\n",
      "Train queries: Queries (7390 queries, 44340 documents, 8 features, 1 max. relevance)\n",
      "Valid queries: Queries (1303 queries, 7818 documents, 8 features, 1 max. relevance)\n",
      "Test queries: Queries (1307 queries, 7842 documents, 8 features, 1 max. relevance)\n",
      "Train queries: Queries (4245 queries, 25470 documents, 8 features, 1 max. relevance)\n",
      "Valid queries: Queries (692 queries, 4152 documents, 8 features, 1 max. relevance)\n",
      "Test queries: Queries (1307 queries, 7842 documents, 8 features, 1 max. relevance)\n",
      "nDCG@3 on the test queries: 0.41658258\n",
      "Train queries: Queries (7390 queries, 44340 documents, 8 features, 1 max. relevance)\n",
      "Valid queries: Queries (1250 queries, 7500 documents, 8 features, 1 max. relevance)\n",
      "Test queries: Queries (1360 queries, 8160 documents, 8 features, 1 max. relevance)\n",
      "Train queries: Queries (4075 queries, 24450 documents, 8 features, 1 max. relevance)\n",
      "Valid queries: Queries (631 queries, 3786 documents, 8 features, 1 max. relevance)\n",
      "Test queries: Queries (1360 queries, 8160 documents, 8 features, 1 max. relevance)\n",
      "nDCG@3 on the test queries: 0.43234178\n",
      "Train queries: Queries (7444 queries, 44664 documents, 8 features, 1 max. relevance)\n",
      "Valid queries: Queries (1249 queries, 7494 documents, 8 features, 1 max. relevance)\n",
      "Test queries: Queries (1307 queries, 7842 documents, 8 features, 1 max. relevance)\n",
      "Train queries: Queries (4236 queries, 25416 documents, 8 features, 1 max. relevance)\n",
      "Valid queries: Queries (646 queries, 3876 documents, 8 features, 1 max. relevance)\n",
      "Test queries: Queries (1307 queries, 7842 documents, 8 features, 1 max. relevance)\n",
      "nDCG@3 on the test queries: 0.42402390\n",
      "Train queries: Queries (7347 queries, 44082 documents, 8 features, 1 max. relevance)\n",
      "Valid queries: Queries (1304 queries, 7824 documents, 8 features, 1 max. relevance)\n",
      "Test queries: Queries (1349 queries, 8094 documents, 8 features, 1 max. relevance)\n",
      "Train queries: Queries (4336 queries, 26016 documents, 8 features, 1 max. relevance)\n",
      "Valid queries: Queries (673 queries, 4038 documents, 8 features, 1 max. relevance)\n",
      "Test queries: Queries (1349 queries, 8094 documents, 8 features, 1 max. relevance)\n",
      "nDCG@3 on the test queries: 0.44444475\n",
      "Train queries: Queries (7282 queries, 43692 documents, 8 features, 1 max. relevance)\n",
      "Valid queries: Queries (1263 queries, 7578 documents, 8 features, 1 max. relevance)\n",
      "Test queries: Queries (1455 queries, 8730 documents, 8 features, 1 max. relevance)\n",
      "Train queries: Queries (4106 queries, 24636 documents, 8 features, 1 max. relevance)\n",
      "Valid queries: Queries (685 queries, 4110 documents, 8 features, 1 max. relevance)\n",
      "Test queries: Queries (1455 queries, 8730 documents, 8 features, 1 max. relevance)\n",
      "nDCG@3 on the test queries: 0.43512075\n",
      "Train queries: Queries (7383 queries, 44298 documents, 8 features, 1 max. relevance)\n",
      "Valid queries: Queries (1249 queries, 7494 documents, 8 features, 1 max. relevance)\n",
      "Test queries: Queries (1368 queries, 8208 documents, 8 features, 1 max. relevance)\n",
      "Train queries: Queries (4054 queries, 24324 documents, 8 features, 1 max. relevance)\n",
      "Valid queries: Queries (647 queries, 3882 documents, 8 features, 1 max. relevance)\n",
      "Test queries: Queries (1368 queries, 8208 documents, 8 features, 1 max. relevance)\n",
      "nDCG@3 on the test queries: 0.40893713\n",
      "Train queries: Queries (7339 queries, 44034 documents, 8 features, 1 max. relevance)\n",
      "Valid queries: Queries (1314 queries, 7884 documents, 8 features, 1 max. relevance)\n",
      "Test queries: Queries (1347 queries, 8082 documents, 8 features, 1 max. relevance)\n",
      "Train queries: Queries (4132 queries, 24792 documents, 8 features, 1 max. relevance)\n",
      "Valid queries: Queries (676 queries, 4056 documents, 8 features, 1 max. relevance)\n",
      "Test queries: Queries (1347 queries, 8082 documents, 8 features, 1 max. relevance)\n",
      "nDCG@3 on the test queries: 0.42067250\n",
      "Train queries: Queries (7347 queries, 44082 documents, 8 features, 1 max. relevance)\n",
      "Valid queries: Queries (1293 queries, 7758 documents, 8 features, 1 max. relevance)\n",
      "Test queries: Queries (1360 queries, 8160 documents, 8 features, 1 max. relevance)\n",
      "Train queries: Queries (4286 queries, 25716 documents, 8 features, 1 max. relevance)\n",
      "Valid queries: Queries (704 queries, 4224 documents, 8 features, 1 max. relevance)\n",
      "Test queries: Queries (1360 queries, 8160 documents, 8 features, 1 max. relevance)\n",
      "nDCG@3 on the test queries: 0.43450607\n",
      "Train queries: Queries (7298 queries, 43788 documents, 8 features, 1 max. relevance)\n",
      "Valid queries: Queries (1338 queries, 8028 documents, 8 features, 1 max. relevance)\n",
      "Test queries: Queries (1364 queries, 8184 documents, 8 features, 1 max. relevance)\n",
      "Train queries: Queries (4128 queries, 24768 documents, 8 features, 1 max. relevance)\n",
      "Valid queries: Queries (729 queries, 4374 documents, 8 features, 1 max. relevance)\n",
      "Test queries: Queries (1364 queries, 8184 documents, 8 features, 1 max. relevance)\n",
      "nDCG@3 on the test queries: 0.43370110\n",
      "Train queries: Queries (7301 queries, 43806 documents, 8 features, 1 max. relevance)\n",
      "Valid queries: Queries (1335 queries, 8010 documents, 8 features, 1 max. relevance)\n",
      "Test queries: Queries (1364 queries, 8184 documents, 8 features, 1 max. relevance)\n",
      "Train queries: Queries (4005 queries, 24030 documents, 8 features, 1 max. relevance)\n",
      "Valid queries: Queries (692 queries, 4152 documents, 8 features, 1 max. relevance)\n",
      "Test queries: Queries (1364 queries, 8184 documents, 8 features, 1 max. relevance)\n",
      "nDCG@3 on the test queries: 0.41847980\n",
      "Train queries: Queries (7377 queries, 44262 documents, 8 features, 1 max. relevance)\n",
      "Valid queries: Queries (1276 queries, 7656 documents, 8 features, 1 max. relevance)\n",
      "Test queries: Queries (1347 queries, 8082 documents, 8 features, 1 max. relevance)\n",
      "Train queries: Queries (4209 queries, 25254 documents, 8 features, 1 max. relevance)\n",
      "Valid queries: Queries (682 queries, 4092 documents, 8 features, 1 max. relevance)\n",
      "Test queries: Queries (1347 queries, 8082 documents, 8 features, 1 max. relevance)\n",
      "nDCG@3 on the test queries: 0.43048515\n",
      "Train queries: Queries (7340 queries, 44040 documents, 8 features, 1 max. relevance)\n",
      "Valid queries: Queries (1293 queries, 7758 documents, 8 features, 1 max. relevance)\n",
      "Test queries: Queries (1367 queries, 8202 documents, 8 features, 1 max. relevance)\n",
      "Train queries: Queries (4153 queries, 24918 documents, 8 features, 1 max. relevance)\n",
      "Valid queries: Queries (684 queries, 4104 documents, 8 features, 1 max. relevance)\n",
      "Test queries: Queries (1367 queries, 8202 documents, 8 features, 1 max. relevance)\n",
      "nDCG@3 on the test queries: 0.43814434\n"
     ]
    }
   ],
   "source": [
    "for i in range(16):\n",
    "    \n",
    "    training_queries = Queries.load_from_text('data/svmlight_training_{0}.txt'.format(i))\n",
    "    validation_queries = Queries.load_from_text('data/svmlight_validation_{0}.txt'.format(i))\n",
    "    test_queries = Queries.load_from_text('data/svmlight_test_{0}.txt'.format(i))\n",
    "\n",
    "    # Print basic info about query datasets.\n",
    "    print('Train queries: %s' % training_queries)\n",
    "    print('Valid queries: %s' % validation_queries)\n",
    "    print('Test queries: %s' % test_queries)\n",
    "    \n",
    "    # Set this to True in order to remove queries containing all documents\n",
    "    # of the same relevance score -- these are useless for LambdaMART.\n",
    "    remove_useless_queries = True\n",
    "\n",
    "    # Find constant query-document features.\n",
    "    cfs = find_constant_features([training_queries, validation_queries, test_queries])\n",
    "\n",
    "    # Get rid of constant features and (possibly) remove useless queries.\n",
    "    training_queries.adjust(remove_features=cfs, purge=remove_useless_queries)\n",
    "    validation_queries.adjust(remove_features=cfs, purge=remove_useless_queries)\n",
    "    test_queries.adjust(remove_features=cfs)\n",
    "\n",
    "    # Print basic info about query datasets.\n",
    "    print('Train queries: %s' % training_queries)\n",
    "    print('Valid queries: %s' % validation_queries)\n",
    "    print('Test queries: %s' % test_queries)\n",
    "    \n",
    "    model = LambdaMART(metric='nDCG@3', max_leaf_nodes=7, shrinkage=0.1,\n",
    "                   estopping=50, n_jobs=-1, min_samples_leaf=50,\n",
    "                   random_state=42)\n",
    "\n",
    "    model.fit(training_queries, validation_queries=validation_queries)\n",
    "    \n",
    "    print('%s on the test queries: %.8f'\n",
    "             % (model.metric, model.evaluate(test_queries, n_jobs=1)))\n",
    "\n",
    "    model.save('models/lambdamart_{0}_{1}'.format(model.metric, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prediction = model.predict(test_queries, compact=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(model, features, queries):\n",
    "    \n",
    "    pred = []\n",
    "    \n",
    "    prediction = model.predict(queries, compact=True, n_jobs=-1)\n",
    "    \n",
    "    print('Getting place ids...')\n",
    "    \n",
    "    place_ids = features['place_id'].values\n",
    "    \n",
    "    for index, qid in enumerate(queries.query_ids):\n",
    "        \n",
    "        query_range = range(queries.query_indptr[index], queries.query_indptr[index+1])\n",
    "        # get 3 highest prediction scores for each query\n",
    "        docs = prediction[query_range].argsort()[-3:][::-1]\n",
    "        query_place_ids = place_ids[query_range][docs]\n",
    "        query_place_ids = map(str, query_place_ids)\n",
    "        query_place_ids = ' '.join(query_place_ids)\n",
    "        pred.append([qid, query_place_ids])\n",
    "        \n",
    "        '''docs = prediction[index].argsort()[-3:][::-1]\n",
    "        place_ids = features[features.row_id == qid]['place_id'].iloc[docs].apply(str).str.cat(sep=' ')\n",
    "        pred.append([qid, place_ids])'''\n",
    "        \n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading features 0...\n",
      "Loading queries 0...\n",
      "Queries: Queries (535822 queries, 2679110 documents, 8 features, 0 max. relevance)\n",
      "Loading model 0...\n",
      "Prediction 0...\n",
      "Getting place ids...\n",
      "Loading features 1...\n",
      "Loading queries 1...\n",
      "Queries: Queries (537340 queries, 2686700 documents, 8 features, 0 max. relevance)\n",
      "Loading model 1...\n",
      "Prediction 1...\n",
      "Getting place ids...\n",
      "Loading features 2...\n",
      "Loading queries 2...\n",
      "Queries: Queries (544336 queries, 2721680 documents, 8 features, 0 max. relevance)\n",
      "Loading model 2...\n",
      "Prediction 2...\n",
      "Getting place ids...\n",
      "Loading features 3...\n",
      "Loading queries 3...\n",
      "Queries: Queries (531828 queries, 2659140 documents, 8 features, 0 max. relevance)\n",
      "Loading model 3...\n",
      "Prediction 3...\n",
      "Getting place ids...\n",
      "Loading features 4...\n",
      "Loading queries 4...\n",
      "Queries: Queries (529968 queries, 2649840 documents, 8 features, 0 max. relevance)\n",
      "Loading model 4...\n",
      "Prediction 4...\n",
      "Getting place ids...\n",
      "Loading features 5...\n",
      "Loading queries 5...\n",
      "Queries: Queries (544254 queries, 2721270 documents, 8 features, 0 max. relevance)\n",
      "Loading model 5...\n",
      "Prediction 5...\n",
      "Getting place ids...\n",
      "Loading features 6...\n",
      "Loading queries 6...\n",
      "Queries: Queries (553229 queries, 2766145 documents, 8 features, 0 max. relevance)\n",
      "Loading model 6...\n",
      "Prediction 6...\n",
      "Getting place ids...\n",
      "Loading features 7...\n",
      "Loading queries 7...\n",
      "Queries: Queries (525973 queries, 2629865 documents, 8 features, 0 max. relevance)\n",
      "Loading model 7...\n",
      "Prediction 7...\n",
      "Getting place ids...\n",
      "Loading features 8...\n",
      "Loading queries 8...\n",
      "Queries: Queries (523834 queries, 2619170 documents, 8 features, 0 max. relevance)\n",
      "Loading model 8...\n",
      "Prediction 8...\n",
      "Getting place ids...\n",
      "Loading features 9...\n",
      "Loading queries 9...\n",
      "Queries: Queries (537855 queries, 2689275 documents, 8 features, 0 max. relevance)\n",
      "Loading model 9...\n",
      "Prediction 9...\n",
      "Getting place ids...\n",
      "Loading features 10...\n",
      "Loading queries 10...\n",
      "Queries: Queries (543495 queries, 2717475 documents, 8 features, 0 max. relevance)\n",
      "Loading model 10...\n",
      "Prediction 10...\n",
      "Getting place ids...\n",
      "Loading features 11...\n",
      "Loading queries 11...\n",
      "Queries: Queries (542430 queries, 2712150 documents, 8 features, 0 max. relevance)\n",
      "Loading model 11...\n",
      "Prediction 11...\n",
      "Getting place ids...\n",
      "Loading features 12...\n",
      "Loading queries 12...\n",
      "Queries: Queries (545010 queries, 2725050 documents, 8 features, 0 max. relevance)\n",
      "Loading model 12...\n",
      "Prediction 12...\n",
      "Getting place ids...\n",
      "Loading features 13...\n",
      "Loading queries 13...\n",
      "Queries: Queries (559996 queries, 2799980 documents, 8 features, 0 max. relevance)\n",
      "Loading model 13...\n",
      "Prediction 13...\n",
      "Getting place ids...\n",
      "Loading features 14...\n",
      "Loading queries 14...\n",
      "Queries: Queries (531681 queries, 2658405 documents, 8 features, 0 max. relevance)\n",
      "Loading model 14...\n",
      "Prediction 14...\n",
      "Getting place ids...\n",
      "Loading features 15...\n",
      "Loading queries 15...\n",
      "Queries: Queries (520179 queries, 2600895 documents, 8 features, 0 max. relevance)\n",
      "Loading model 15...\n",
      "Prediction 15...\n",
      "Getting place ids...\n",
      "Generating submission...\n"
     ]
    }
   ],
   "source": [
    "predictions = []\n",
    "\n",
    "for i in range(16):\n",
    "    \n",
    "    print('Loading features {0}...'.format(i))\n",
    "    features = pandas.read_csv('data/features_test_{0}.csv'.format(i))\n",
    "    features.sort_values('row_id', inplace=True)\n",
    "\n",
    "    print('Loading queries {0}...'.format(i))\n",
    "    queries = Queries.load_from_text('data/svmlight_unlabeled_{0}.txt'.format(i))\n",
    "    #queries = Queries.load_from_text('data/svmlight_unlabeled_{0}.txt'.format('test'))\n",
    "    print('Queries: %s' % queries)\n",
    "    \n",
    "    print('Loading model {0}...'.format(i))\n",
    "    model = LambdaMART.load('models/lambdamart_{0}_{1}'.format('nDCG@3', i))\n",
    "    \n",
    "    print('Prediction {0}...'.format(i))\n",
    "    #prediction = model.predict(queries, compact=False)\n",
    "    predictions.extend(predict(model, features, queries))\n",
    "    \n",
    "print('Generating submission...')\n",
    "submission = pandas.DataFrame(predictions, columns=['row_id', 'place_id'])\n",
    "submission.sort_values('row_id', inplace=True)\n",
    "\n",
    "submission.to_csv('submission_lambdamart.gz', index=False, compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Submission size ok?', True)\n"
     ]
    }
   ],
   "source": [
    "print(\"Submission size ok?\", submission.shape[0] == 8607230)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1347844674159942"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def apk(actual, predicted, k=10):\n",
    "    \"\"\"\n",
    "    Computes the average precision at k.\n",
    "    This function computes the average prescision at k between two lists of\n",
    "    items.\n",
    "    Parameters\n",
    "    ----------\n",
    "    actual : list\n",
    "             A list of elements that are to be predicted (order doesn't matter)\n",
    "    predicted : list\n",
    "                A list of predicted elements (order does matter)\n",
    "    k : int, optional\n",
    "        The maximum number of predicted elements\n",
    "    Returns\n",
    "    -------\n",
    "    score : double\n",
    "            The average precision at k over the input lists\n",
    "    \"\"\"\n",
    "    \n",
    "    if len(predicted)>k:\n",
    "        predicted = predicted[:k]\n",
    "\n",
    "    score = 0.0\n",
    "    num_hits = 0.0\n",
    "\n",
    "    for i,p in enumerate(predicted):\n",
    "        #print(i, p, actual, predicted)\n",
    "        if p in actual and p not in predicted[:i]:\n",
    "            num_hits += 1.0\n",
    "            score += num_hits / (i+1.0)\n",
    "\n",
    "    if not actual:\n",
    "        return 0.0\n",
    "\n",
    "    return score / min(len(actual), k)\n",
    "\n",
    "def mapk(actual, predicted, k=10):\n",
    "    \"\"\"\n",
    "    Computes the mean average precision at k.\n",
    "    This function computes the mean average prescision at k between two lists\n",
    "    of lists of items.\n",
    "    Parameters\n",
    "    ----------\n",
    "    actual : list\n",
    "             A list of lists of elements that are to be predicted \n",
    "             (order doesn't matter in the lists)\n",
    "    predicted : list\n",
    "                A list of lists of predicted elements\n",
    "                (order matters in the lists)\n",
    "    k : int, optional\n",
    "        The maximum number of predicted elements\n",
    "    Returns\n",
    "    -------\n",
    "    score : double\n",
    "            The mean average precision at k over the input lists\n",
    "    \"\"\"\n",
    "    return np.mean([apk(a,p,k) for a,p in zip(actual, predicted)])\n",
    "\n",
    "def format_prediction(x):\n",
    "    if isinstance(x, str):\n",
    "        return x.split()\n",
    "    return []\n",
    "\n",
    "score = mapk(val['place_id'].map(lambda x : str(x)), val['predicted'].map(lambda x: format_prediction(x)), k=3)\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction size ok? False\n"
     ]
    }
   ],
   "source": [
    "#predictions = pd.concat([val['row_id'], val['predicted']], axis=1, keys=['row_id', 'place_id'])\n",
    "#print(\"Prediction size ok?\", predictions.shape[0] == 8607230)\n",
    "#predictions[['row_id', 'place_id']].to_csv('submission.gz', index=False, compression='gzip')\n",
    "test[['row_id','predicted']].to_csv('submission.gz', index=False, compression='gzip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1-NN Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#train = pd.read_csv('train.csv')\n",
    "#test = pd.read_csv('test.csv')\n",
    "\n",
    "tree = KDTree(train[['x', 'y', 'weekhour', 'day']])\n",
    "_, ind = tree.query(test[['x','y', 'weekhour', 'day']], k=1)\n",
    "ind1 = [x[0] for x in ind]\n",
    "test['place_id'] = train.iloc[ind1].place_id.values\n",
    "test[['row_id', 'place_id']].to_csv('submission.gz', index=False, compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_, ind = place_tree.query(test[['x','y']], k=1)\n",
    "ind1 = [x[0] for x in ind]\n",
    "test['place_id'] = agg_place.iloc[ind1].place_id.values\n",
    "test[['row_id', 'place_id']].to_csv('submission_meanxy.gz', index=False, compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "row_id            0.0000\n",
       "x                 0.1675\n",
       "y                 1.3608\n",
       "accuracy        107.0000\n",
       "time         930883.0000\n",
       "weekhour         50.0000\n",
       "dayofyear       282.0000\n",
       "day               9.0000\n",
       "Name: 0, dtype: float64"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.iloc[0] #['place_id'] = 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test['place_id'] = pd.Series(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test[['row_id', 'place_id']].to_csv('submission_spatial_multivariate.gz', index=False, compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Series.count of count    73.0\n",
       "Name: 0, dtype: float64>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "places.iloc[0].row_id.count"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [python2]",
   "language": "python",
   "name": "Python [python2]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
